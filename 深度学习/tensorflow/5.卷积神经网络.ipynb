{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.卷积神经网络.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyO1Ay1xduEUwD/trNxfrx5E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"61qCo2d5FMgm"},"source":["# 从全连接层到卷积"]},{"cell_type":"markdown","metadata":{"id":"pl2rjYy6Gq68"},"source":["*卷积神经网络*（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。"]},{"cell_type":"markdown","metadata":{"id":"tvI-IpD7GydS"},"source":["## 不变性\n","\n","由于沃尔多潜藏的地方并不取决于它的样子。我们可以使用一个“沃尔多检测器”扫描图像，该检测器将图像分成数个小方片，并为每个方片包含沃尔多的可能性打分。而卷积神经网络将“空间不变性”的概念系统化，用较少参数来学习有用的特征。\n","\n","1. 平移不变性：不管出现在图像中的哪个位置，神经网络的底层应该对相同的图像区域做出类似的响应。这个原理即为“平移不变性”。\n","1. 局部性：神经网络的底层应该只探索输入图像中的局部区域，而不考虑图像远处区域的内容，这就是“局部性”原则。最终，这些局部特征可以融会贯通，在整个图像级别上做出预测。\n","\n","让我们看看这是如何转化为数学表示的。"]},{"cell_type":"markdown","metadata":{"id":"44hwADnmIKTz"},"source":["## 限制多层感知机"]},{"cell_type":"markdown","metadata":{"id":"gl_jQ1n-INjl"},"source":["首先，假设以二维图像 $\\mathbf{X}$ 作为输入，那么我们多层感知机的隐藏表示 $\\mathbf{H}$ 在数学上是一个矩阵，在代码中表示为二维张量。\n","其中 $\\mathbf{X}$ 和 $\\mathbf{H}$ 具有相同的形状。\n","我们可以认为，不仅输入有空间结构，隐藏表示也应该有空间结构。\n","我们用  $[\\mathbf{X}]_{i, j}$ 和 $[\\mathbf{H}]_{i, j}$ 分别表示输入图像和隐藏表示中的位置($i$, $j$)处的像素。\n","\n","为了使每个输入像素都有神经元处理，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量 $\\mathsf{W}$。假设 $\\mathbf{U}$ 包含偏置参数，我们可以将全连接层表示为\n","\n","$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n","\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned}$$\n","\n","其中，从 $\\mathsf{W}$ 到 $\\mathsf{V}$ 的转换只是形式的转换，因为在两个四阶张量中，系数之间存在一对一的对应关系。\n","我们只需重新索引下标 $(k, l)$，使 $k = i+a$、$l = j+b$， 由此 $[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$。\n","这里的索引 $a$ 和 $b$ 覆盖了正偏移和负偏移。\n","对于隐藏表示$[\\mathbf{H}]_{i, j}$中的任何给定位置（$i$, $j$），我们通过对 $x$ 中以 $(i, j)$ 为中心的像素，以 $[\\mathsf{V}]{i, j, a, b}$ 作为权重进行加权求和。"]},{"cell_type":"markdown","metadata":{"id":"b1PSLg33IweS"},"source":["### 平移不变性\n","\n","现在让我们用上面的第一个原则：**平移不变性。**\n","这意味着输入 $\\mathbf{X}$ 中的移位，应该仅与隐藏表示 $\\mathbf{H}$ 中的移位相关。也就是说， $\\mathsf{V}$ 和 $\\mathbf{U}$ 实际上不依赖于 $(i, j)$ 的值，即 $[\\mathsf{V}]_{i, j, a, b} = [\\mathbf{V}]_{a, b}$。并且  $\\mathbf{U}$ 是一个常数，比如 $u$。因此，我们可以简化 $\\mathbf{H}$ 定义为：\n","\n","\n","$$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b} [\\mathbf{X}]_{i+a, j+b}.$$\n","\n","\n","这就是卷积。我们使用系数 $[\\mathbf{V}]_{a, b}$ 对位置 $(i, j)$ 附近的像素 $(i+a, j+b)$ 进行加权。\n","注意，$[\\mathbf{V}]_{a, b}$ 的参数比 $[\\mathsf{V}]_{i, j, a, b}$ 少很多，因为前者不再依赖于图像中的位置。"]},{"cell_type":"markdown","metadata":{"id":"3i6ZzSdrJJxF"},"source":["### 局部性\n","\n","现在引用上述的第二个原则：局部性。如上所述，为了收集用来训练参数 $[\\mathbf{H}]_{i, j}$ 的相关信息，我们不应偏离到距 $(i, j)$ 很远的地方。这意味着在 $|a|> \\Delta$ 或 $|b| > \\Delta$ 的范围之外，我们可以设置 $[\\mathbf{V}]_{a, b} = 0$。由此，我们可以将参数 $[\\mathbf{H}]_{i, j}$ 重写为\n","\n","$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n","\n","\n","简而言之，上式是一个卷积层，而卷积神经网络是包含卷积层的一类特殊的神经网络。\n","在深度学习研究社区中， $\\mathbf{V}$ 被称为 *卷积核* （convolution kernel） 或者  *滤波器* （filter），是可学习的权重。\n","当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，多层感知机可能需要数十亿个参数来表示，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。\n","以上所有的权重学习都依赖于归纳偏置，当这种偏置与实际情况相符时，我们就可以得到有效的模型，这些模型能很好地推广到不可见的数据中。\n","但如果这些假设与实际情况不符，比如当图像不满足平移不变时，我们的模型可能难以拟合。"]},{"cell_type":"markdown","metadata":{"id":"19_wMe6BJngT"},"source":["## 卷积\n","\n","在进一步讨论之前，我们先简要回顾一下为什么上面的操作被称为卷积。在数学中，两个函数（比如 $f, g: \\mathbb{R}^d \\to \\mathbb{R}$）之间的*卷积*被定义为\n","\n","$$(f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}.$$\n","\n","也就是说，卷积是测量 $f$ 和 $g$ 之间（把函数“翻转”并移位 $\\mathbf{x}$ 时）的重叠。\n","当我们有离散对象时（即定义域为 $\\mathbb{Z}$ ），积分就变成求和，我们得到以下定义：\n","\n","$$(f * g)(i) = \\sum_a f(a) g(i-a).$$\n","\n","对于二维张量，则为 $f$ 在 $(a, b)$ 和 $g$ 在 $(i-a, j-b)$ 上的对应和：\n","\n","$$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b).$$\n","\n","\n","这看起来类似于，但有一个主要区别：这里不是使用 $(i+a, j+b)$ ，而是使用差值。然而，这种区别是可以化简的，因为我们总是可以匹配局部性里的式子和上式之间的符号。我们在局部性里的式子中的原始定义更正确地描述了*互相关*。我们将在下一节中讨论这一问题。"]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"kUxV-36xFAbT"},"source":["## “沃尔多在哪里” 回顾\n","\n","回到上面的“沃尔多在哪里”游戏，让我们看看它到底是什么样子。卷积层根据滤波器 $\\mathsf{V}$ 选取给定大小的窗口，并加权处理图片，如 :numref:`fig_waldo_mask` 中所示。我们的目标是学习一个模型，以便探测出在“沃尔多”最可能出现的地方。\n","\n","![发现沃尔多。](../img/waldo-mask.jpg)\n",":width:`400px`\n",":label:`fig_waldo_mask`\n","\n","\n","### 通道\n",":label:`subsec_why-conv-channels`\n","\n","然而这种方法有一个问题：我们忽略了图像是由三原色（红色、绿色和蓝色）的组成。\n","实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，例如形状为 $1024 \\times 1024 \\times 3$ 的像素。\n","因此，我们将 $\\mathsf{X}$ 索引为 $[\\mathsf{X}]_{i, j, k}$ 。由此卷积相应地调整为 $[\\mathsf{V}]_{a,b,c}$ ，而不是 $[\\mathbf{V}]_{a,b}$ 。\n","\n","此外，由于输入图像是三维的，我们的隐藏表示 $\\mathsf{H}$ 也是一个三维张量。\n","因此，我们可以把隐藏表示想象为一系列具有二维张量的 *通道* （channel）。\n","这些通道有时也被称为 *特征映射* （feature maps），因为每一层都向后续层提供一组空间化的学习特征。\n","在靠近输入的底层，一些通道专门识别边，而其他通道专门识别纹理。\n","\n","为了支持输入 $\\mathsf{X}$ 和隐藏表示 $\\mathsf{H}$ 中的多个通道，我们可以在 $\\mathsf{V}$ 中添加第四个坐标，即 $[\\mathsf{V}]_{a, b, c, d}$ 。综上所述，\n","\n","$$[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c},$$\n",":eqlabel:`eq_conv-layer-channels`\n","\n","其中隐藏表示 $\\mathsf{H}$ 中的 $d$ 索引表示输出通道，而随后的输出将继续以三维张量 $\\mathsf{H}$ 作为输入进入下一个卷积层。\n","所以， :eqref:`eq_conv-layer-channels` 可以定义具有多个通道的卷积层，而其中 $\\mathsf{V}$ 是该卷积层的权重。\n","\n","然而，仍有许多问题亟待解决。\n","例如，图像中是否到处都有存在沃尔多的可能？如何有效地计算输出层？如何选择适当的激活函数？为了训练有效的网络，如何做出合理的网络设计选择？我们将在本章的其它部分讨论这些问题。\n","\n","\n","\n","## 小结\n","\n","- 图像的平移不变性使我们可以以相同的方式处理局部图像。\n","- 局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。\n","- 在图像处理中，卷积层通常比全连接层需要更少的参数。\n","- 卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。\n","- 多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。"]},{"cell_type":"markdown","metadata":{"id":"RmbtsEFlKyWi"},"source":["# 图像卷积"]},{"cell_type":"markdown","metadata":{"id":"E0hiEW-mg-Tb"},"source":["上节我们解析了卷积层的原理，现在我们看看它的实际应用。由于卷积神经网络的设计是用于探索图像数据，本节我们将以图像为例。\n"]},{"cell_type":"markdown","metadata":{"id":"iV1jfLw7g63v"},"source":["\n","## 互相关运算"]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"TSkrUoKBKkI9"},"source":["\n","\n","\n","\n","\n","严格地说，卷积层所表达的运算可以被更准确地描述为 *互相关运算* (cross-correlation)。\n","根据 :numref:`sec_why-conv` 中的描述，在卷积层中，输入张量和核张量通过互相关运算产生输出张量。\n","\n","首先，我们暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示。在 :numref:`fig_correlation` 中，输入是高度为 $3$ 、宽度为 $3$ 的二维张量（即形状为 $3 \\times 3$ ）。卷积核的高度和宽度都是 $2$ ，而卷积核窗口（或卷积窗口）的形状由内核的高度和宽度决定（即 $2 \\times 2$ ）。\n","\n","![二维互相关运算。阴影部分是第一个输出元素，以及用于计算这个输出的输入和核张量元素：$0\\times0+1\\times1+3\\times2+4\\times3=19$.](http://d2l.ai/_images/correlation.svg)\n",":label:`fig_correlation`\n","\n","在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。\n","当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值。\n","在如上例子中，输出张量的四个元素由二维互相关运算得到，这个输出高度为 $2$ 、宽度为 $2$ ，如下所示：\n","\n","$$\n","0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\\n","1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n","3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n","4\\times0+5\\times1+7\\times2+8\\times3=43.\n","$$\n","\n","注意，输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1，\n","而卷积核只与图像中每个大小完全适合的位置进行互相关运算。\n","所以，**输出大小等于输入大小 $n_h \\times n_w$ 减去卷积核大小 $k_h \\times k_w$，即：**\n","\n","$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\n","\n","这是因为我们需要足够的空间在图像上“移动”卷积核。稍后，我们将看到如何通过在图像边界周围填充零来有保证足够的空间来移动内核，从而保持输出大小不变。\n","接下来，我们在 `corr2d` 函数中实现如上过程，该函数接受输入张量 `X` 和卷积核张量  `K` ，并返回输出张量 `Y` 。\n"]},{"cell_type":"code","metadata":{"id":"IW1CFa2zRBsb","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1617684405140,"user_tz":-480,"elapsed":6434,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"546f1fbd-c3ae-440b-ba50-d1d3b500cfbf"},"source":["!pip install d2l"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting d2l\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/1f/13de7e8cafaba15739caee0596032412aaf51a22726649b317bdb53c4f9a/d2l-0.16.2-py3-none-any.whl (77kB)\n","\r\u001b[K     |████▎                           | 10kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.3MB/s \n","\u001b[?25hRequirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l) (1.1.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l) (3.2.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.2.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (7.6.3)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.3.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (4.10.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.6.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.0.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l) (2.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2.10)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (0.10.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (2.6.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (5.5.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (5.3.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l) (1.0.18)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (5.0.5)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (3.5.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (5.1.2)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (1.0.0)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (4.7.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (2.11.3)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (0.9.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (0.2.0)\n","Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (5.1.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (1.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (1.4.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (3.3.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.4.4)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (1.9.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (22.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->d2l) (1.15.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (54.2.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (0.8.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l) (4.8.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l) (0.2.5)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (2.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l) (1.1.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l) (0.7.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (20.9)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n","Installing collected packages: d2l\n","Successfully installed d2l-0.16.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"origin_pos":4,"tab":["tensorflow"],"id":"vf4wCa1pKkI-","executionInfo":{"status":"ok","timestamp":1617684406959,"user_tz":-480,"elapsed":8250,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["import tensorflow as tf\n","from d2l import tensorflow as d2l\n","\n","def corr2d(X, K):  #@save\n","    \"\"\"计算二维互相关运算。\"\"\"\n","    h, w = K.shape\n","    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            Y[i, j].assign(tf.reduce_sum(X[i:i + h, j:j + w] * K))\n","    return Y"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":5,"id":"4htFXrnXKkI-"},"source":["通过 :numref:`fig_correlation` 的输入张量 `X` 和卷积核张量 `K` ，我们来验证一下上述二维互相关运算的输出。\n"]},{"cell_type":"code","metadata":{"origin_pos":6,"tab":["tensorflow"],"id":"XOx-PKRpKkI-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684406961,"user_tz":-480,"elapsed":8111,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"1c7e0fc0-1502-49a5-ee13-bd87b9534156"},"source":["X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","K = tf.constant([[0.0, 1.0], [2.0, 3.0]])\n","corr2d(X, K)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[19., 25.],\n","       [37., 43.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"origin_pos":7,"id":"itf-p2nEKkI_"},"source":["## 卷积层\n","\n","卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。\n","所以，***卷积层中的两个被训练的参数是卷积核权重和标量偏置。***\n","就像我们之前随机初始化全连接层一样，在训练基于卷积层的模型时，我们也随机初始化卷积核权重\n","\n","基于上面定义的 `corr2d` 函数实现二维卷积层。在 `__init__` 构造函数中，将 `weight` 和 `bias` 声明为两个模型参数。前向传播函数调用 `corr2d` 函数并添加偏置。\n"]},{"cell_type":"code","metadata":{"origin_pos":10,"tab":["tensorflow"],"id":"-i-mdSi5KkI_","executionInfo":{"status":"ok","timestamp":1617684406962,"user_tz":-480,"elapsed":8110,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["class Conv2D(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def build(self, kernel_size):\n","        initializer = tf.random_normal_initializer()\n","        self.weight = self.add_weight(name='w', shape=kernel_size,\n","                                      initializer=initializer)\n","        self.bias = self.add_weight(name='b', shape=(1,),\n","                                    initializer=initializer)\n","\n","    def call(self, inputs):\n","        return corr2d(inputs, self.weight) + self.bias"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":11,"id":"zMzHWku3KkI_"},"source":["高度和宽度分别为 $h$ 和 $w$的卷积核可以被称为 $h \\times w$ 卷积或 $h \\times w$ 卷积核。\n","我们也将带有 $h \\times w$ 卷积核的卷积层称为 $h \\times w$ 卷积层\n","\n","\n","## 图像中目标的边缘检测\n","\n","如下是卷积层的一个简单应用：通过找到像素变化的位置来检测图像中不同颜色的边缘。\n","首先，我们构造一个 $6\\times 8$ 像素的黑白图像。中间四列为黑色（$0$），其余像素为白色（$1$）。\n"]},{"cell_type":"code","metadata":{"origin_pos":13,"tab":["tensorflow"],"id":"FzuCUvcbKkJA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684406962,"user_tz":-480,"elapsed":8102,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"43702bd0-c65a-44c7-a65c-a15b9ae2a4b7"},"source":["X = tf.Variable(tf.ones((6, 8)))\n","X[:, 2:6].assign(tf.zeros(X[:, 2:6].shape))\n","X"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(6, 8) dtype=float32, numpy=\n","array([[1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"origin_pos":14,"id":"IH0govQgKkJA"},"source":["接下来，我们构造一个高度为 $1$ 、宽度为 $2$ 的卷积核 `K` 。当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零。\n"]},{"cell_type":"code","metadata":{"origin_pos":15,"tab":["tensorflow"],"id":"QhJfYlpyKkJA","executionInfo":{"status":"ok","timestamp":1617684406962,"user_tz":-480,"elapsed":8101,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["K = tf.constant([[1.0, -1.0]])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":16,"id":"ZA_iN1HoKkJA"},"source":["现在，我们对参数 `X` （输入）和 `K` （卷积核）执行互相关运算。\n","如下所示，输出 `Y` 中的 $1$ 代表从白色到黑色的边缘， $-1$ 代表从黑色到白色的边缘，其他情况的输出为 $0$\n"]},{"cell_type":"code","metadata":{"origin_pos":17,"tab":["tensorflow"],"id":"FdVs2V0vKkJA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684406963,"user_tz":-480,"elapsed":8094,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"fbf1a83c-1508-4d52-d569-ae01a89aa79a"},"source":["Y = corr2d(X, K)\n","Y"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(6, 7) dtype=float32, numpy=\n","array([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"origin_pos":18,"id":"vtrx9w1lKkJB"},"source":["现在我们将输入的二维图像转置，再进行如上的互相关运算。\n","其输出如下，之前检测到的垂直边缘消失了。\n","不出所料，这个卷积核 `K` 只可以检测垂直边缘，无法检测水平边缘。\n"]},{"cell_type":"code","metadata":{"origin_pos":19,"tab":["tensorflow"],"id":"vF32SJT2KkJB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684406963,"user_tz":-480,"elapsed":8087,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"5850887e-25c1-4971-b4e9-a278ca6924da"},"source":["corr2d(tf.transpose(X), K)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(8, 5) dtype=float32, numpy=\n","array([[0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"origin_pos":20,"id":"VZXGgznQKkJB"},"source":["## 学习卷积核\n","\n","如果我们只需寻找黑白边缘，那么以上 `[1, -1]` 的边缘检测器足以。然而，当有了更复杂数值的卷积核，或者连续的卷积层时，我们不可能手动设计过滤器。那么我们是否可以学习由  `X` 生成 `Y` 的卷积核呢？\n","\n","现在让我们看看是否可以通过仅查看“输入-输出”对来了解由 `X` 生成 `Y` 的卷积核。\n","我们先构造一个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较  `Y` 与卷积层输出的平方误差，然后计算梯度来更新卷积核。为了简单起见，我们在此使用内置的二维卷积层，并忽略偏置。\n"]},{"cell_type":"code","metadata":{"origin_pos":23,"tab":["tensorflow"],"id":"DYiGEor0KkJB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407767,"user_tz":-480,"elapsed":8884,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"2c00fc82-c040-4164-b570-008052e7a094"},"source":["# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核\n","conv2d = tf.keras.layers.Conv2D(1, (1, 2), use_bias=False)\n","\n","# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），\n","# 其中批量大小和通道数都为1\n","X = tf.reshape(X, (1, 6, 8, 1))\n","Y = tf.reshape(Y, (1, 6, 7, 1))\n","\n","Y_hat = conv2d(X)\n","for i in range(10):\n","    with tf.GradientTape(watch_accessed_variables=False) as g:\n","        g.watch(conv2d.weights[0])\n","        Y_hat = conv2d(X)\n","        l = (abs(Y_hat - Y))**2\n","        # 迭代卷积核\n","        update = tf.multiply(3e-2, g.gradient(l, conv2d.weights[0]))\n","        weights = conv2d.get_weights()\n","        weights[0] = conv2d.weights[0] - update\n","        conv2d.set_weights(weights)\n","        if (i + 1) % 2 == 0:\n","            print(f'batch {i+1}, loss {tf.reduce_sum(l):.3f}')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["batch 2, loss 12.536\n","batch 4, loss 2.955\n","batch 6, loss 0.845\n","batch 8, loss 0.285\n","batch 10, loss 0.106\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":24,"id":"gMURIOvWKkJC"},"source":["在 $10$ 次迭代之后，误差已经降到足够低。现在我们来看看我们所学的卷积核的权重张量。\n"]},{"cell_type":"code","metadata":{"origin_pos":27,"tab":["tensorflow"],"id":"jGfbzjDZKkJC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407768,"user_tz":-480,"elapsed":8877,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"878b7334-888f-46b2-b5b2-a933307e15fc"},"source":["tf.reshape(conv2d.get_weights()[0], (1, 2))"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.95186746, -1.0169064 ]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"origin_pos":28,"id":"ChwNIy3AKkJC"},"source":["细心的你一定会发现，我们学习到的卷积核权重非常接近我们之前定义的卷积核 `K` 。\n","\n","\n","## 互相关和卷积\n","\n","回想一下我们在 :numref:`sec_why-conv` 中观察到的互相关和卷积运算之间的对应关系。\n","为了得到严格*卷积*运算输出，我们需要执行 :eqref:`eq_2d-conv-discrete` 中定义的严格卷积运算，而不是互相关运算。\n","幸运的是，它们差别不大，我们只需水平和垂直翻转二维卷积核张量，然后对输入张量执行*互相关*运算。\n","\n","值得注意的是，由于卷积核是从数据中学习到的，因此无论这些层执行严格的卷积运算还是互相关运算，卷积层的输出都不会受到影响。\n","为了说明这一点，假设卷积层执行*互相关*运算并学习 :numref:`fig_correlation` 中的卷积核，该卷积核在这里由矩阵 $\\mathbf{K}$ 表示。\n","假设其他条件不变，当这个层执行严格的*卷积*时，学习的卷积核 $\\mathbf{K}'$ 在水平和垂直翻转之后将与 $\\mathbf{K}$ 相同。\n","也就是说，当卷积层对 :numref:`fig_correlation` 中的输入和 $\\mathbf{K}'$ 执行严格*卷积*运算时，将得到与互相关运算 :numref:`fig_correlation` 中相同的输出。\n","\n","为了与深度学习文献中的标准术语保持一致，我们将继续把“互相关运算”称为卷积运算，尽管严格地说，它们略有不同。\n","此外，对于卷积核张量上的权重，我们称其为*元素*。\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-S8IaixuMy1H"},"source":["## 特征映射和感受野\n","\n","如在 :numref:`subsec_why-conv-channels` 中所述， :numref:`fig_correlation` 中输出的卷积层有时被称为 *特征映射* （Feature Map），因为它可以被视为一个输入映射到下一层的空间维度的转换器。\n","在CNN中，对于某一层的任意元素 $x$ ，其 *感受野* （Receptive Field）是指在前向传播期间可能影响 $x$ 计算的所有元素（来自所有先前层）。\n","\n","注意，感受野的覆盖率可能大于某层输入的实际区域大小。让我们用 :numref:`fig_correlation` 为例来解释感受野：\n","给定 $2 \\times 2$ 卷积核，阴影输出元素值 $19$ 的接收域是输入阴影部分的四个元素。\n","假设之前输出为 $\\mathbf{Y}$ ，其大小为 $2 \\times 2$ ，现在我们在其后附加一个卷积层，该卷积层以 $\\mathbf{Y}$ 为输入，输出单个元素 $z$。\n","在这种情况下， $\\mathbf{Y}$ 上的 $z$ 的接收字段包括 $\\mathbf{Y}$ 的所有四个元素，而输入的感受野包括最初所有九个输入元素。\n","因此，当一个特征图中的任意元素需要检测更广区域的输入特征时，我们可以构建一个更深的网络。"]},{"cell_type":"markdown","metadata":{"id":"wiST8UlNMwqH"},"source":["## 小结\n","\n","* 二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。\n","* 我们可以设计一个卷积核来检测图像的边缘。\n","* 我们可以从数据中学习卷积核的参数。\n","* 学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。\n","* 当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。"]},{"cell_type":"markdown","metadata":{"id":"sr_K23RgM-J9"},"source":["# 填充和步幅"]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"ceKCWe_1M4qs"},"source":["\n","\n","\n","在前面的例子 :numref:`fig_correlation` 中，输入的高度和宽度都为$3$，卷积核的高度和宽度都为 $2$ ，生成的输出表征的维数为 $2\\times2$。\n","正如我们在 :numref:`sec_conv_layer` 中所概括的那样，假设输入形状为 $n_h\\times n_w$，卷积核形状为 $k_h\\times k_w$，那么输出形状将是 $(n_h-k_h+1) \\times (n_w-k_w+1)$。\n","因此，卷积的输出形状取决于输入形状和卷积核的形状。\n","\n","还有什么因素会影响输出的大小呢？本节我们将介绍 *填充*（padding）和 *步幅* (stride)。假设以下情景：\n","- 有时，在应用了连续的卷积之后，我们最终得到的输出远小于输入大小。这是由于卷积核的宽度和高度通常大于 $1$ 所导致的。比如，一个 $240 \\times 240$ 像素的图像，经过 $10$ 层 $5 \\times 5$ 的卷积后，将减少到 $200 \\times 200$ 像素。如此一来，原始图像的边界丢失了许多有用信息。 而*填充* 是解决此问题最有效的方法。\n","- 有时，我们可能希望大幅降低图像的宽度和高度。例如，如果我们发现原始的输入分辨率十分冗余。 *步幅*则可以在这类情况下提供帮助。\n","\n","\n","\n","## 填充\n","\n","如上所述，在应用多层卷积时，我们常常丢失边缘像素。\n","由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。\n","但随着我们应用许多连续卷积层，累积丢失的像素数就多了。\n","解决这个问题的简单方法即为*填充*（padding）：在输入图像的边界填充元素（通常填充元素是 $0$ ）。\n","例如，在 :numref:`img_conv_pad` 中，我们将 $3 \\times 3$ 输入填充到 $5 \\times 5$，那么它的输出就增加为 $4 \\times 4$。阴影部分是第一个输出元素以及用于输出计算的输入和核张量元素：\n","$0\\times0+0\\times1+0\\times2+0\\times3=0$。\n","\n","![带填充的二维互相关。](../img/conv-pad.svg)\n",":label:`img_conv_pad`\n","\n","通常，如果我们添加 $p_h$ 行填充（大约一半在顶部，一半在底部）和 $p_w$ 列填充（左侧大约一半，右侧半），则输出形状将为\n","\n","$$(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1)。$$\n","\n","这意味着输出的高度和宽度将分别增加 $p_h$ 和 $p_w$。\n","\n","**在许多情况下，我们需要设置 $p_h=k_h-1$ 和 $p_w=k_w-1$，使输入和输出具有相同的高度和宽度。**\n","这样可以在构建网络时更容易地预测每个图层的输出形状。假设 $k_h$ 是奇数，我们将在高度的两侧填充 $p_h/2$ 行。\n","如果 $k_h$ 是偶数，则一种可能性是在输入顶部填充 $\\lceil p_h/2\\rceil$ 行，在底部填充 $\\lfloor p_h/2\\rfloor$ 行。同理，我们填充宽度的两侧。\n","\n","卷积神经网络中卷积核的高度和宽度通常为奇数，例如 1、3、5 或 7。\n","选择奇数的好处是，保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。\n","\n","此外，使用奇数核和填充也提供了书写上的便利。对于任何二维张量 `X`，当满足：\n","1. 内核的大小是奇数；\n","2. 所有边的填充行数和列数相同；\n","3. 输出与输入具有相同高度和宽度\n","则可以得出：输出 `Y[i, j]` 是通过以输入 `X[i, j]` 为中心，与卷积核进行互相关计算。\n","\n","比如，在下面的例子中，我们创建一个高度和宽度为3的二维卷积层，并在所有侧边填充 1 个像素。给定高度和宽度为 $8$ 的输入，则输出的高度和宽度也是 8。\n"]},{"cell_type":"code","metadata":{"origin_pos":3,"tab":["tensorflow"],"id":"YlJ4I3PKM4qv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407768,"user_tz":-480,"elapsed":8870,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"9ef1d807-80eb-4a39-8127-4349f82b8d2e"},"source":["import tensorflow as tf\n","\n","# 为了方便起见，我们定义了一个计算卷积层的函数。\n","# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n","def comp_conv2d(conv2d, X):\n","    # 这里的（1，1）表示批量大小和通道数都是1\n","    X = tf.reshape(X, (1,) + X.shape + (1,))\n","    Y = conv2d(X)\n","    # 省略前两个维度：批量大小和通道\n","    return tf.reshape(Y, Y.shape[1:3])\n","\n","# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列\n","conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same') # 卷积核个数，卷积核形状\n","# 补0策略，为“valid”, “same”。“valid”代表只进行有效的卷积，即对边界数据不处理。\n","# “same”代表保留边界处的卷积结果，通常会导致输出shape与输入shape相同。\n","X = tf.random.uniform(shape=(8, 8))\n","comp_conv2d(conv2d, X).shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([8, 8])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"origin_pos":4,"id":"0CanpZogM4qx"},"source":["当卷积内核的高度和宽度不同时，我们可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度。在如下示例中，我们使用高度为 $5$，宽度为 $3$ 的卷积核，高度和宽度两边的填充分别为 $2$ 和 $1$。\n"]},{"cell_type":"code","metadata":{"origin_pos":7,"tab":["tensorflow"],"id":"YTxMaZb8M4qx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407768,"user_tz":-480,"elapsed":8863,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"120caa13-00c0-41fd-ee62-0c4e9d20c96d"},"source":["conv2d = tf.keras.layers.Conv2D(1, kernel_size=(5, 3), padding='valid')\n","comp_conv2d(conv2d, X).shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([4, 6])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"origin_pos":8,"id":"tespnpDwM4qx"},"source":["## 步幅\n","\n","在计算互相关时，卷积窗口从输入张量的左上角开始，向下和向右滑动。\n","在前面的例子中，我们默认每次滑动一个元素。\n","但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。\n","\n","我们将每次滑动元素的数量称为 *步幅* （stride）。到目前为止，我们只使用过高度或宽度为 $1$ 的步幅，那么如何使用较大的步幅呢？\n",":numref:`img_conv_stride` 是垂直步幅为 $3$，水平步幅为 $2$ 的二维互相关运算。\n","着色部分是输出元素以及用于输出计算的输入和内核张量元素：$0\\times0+0\\times1+1\\times2+2\\times3=8$、$0\\times0+6\\times1+0\\times2+0\\times3=6$。\n","\n","如何计算输出中第一列的第二个元素呢？如图所示，卷积窗口向下滑动三行、向右滑动两列。但是，当卷积窗口继续向右滑动两列时，没有输出，因为输入元素无法填充窗口（除非我们添加另一列填充）。\n","\n","![垂直步幅为 $3$，水平步幅为 $2$ 的二维互相关运算。](../img/conv-stride.svg)\n",":label:`img_conv_stride`\n","\n","通常，当垂直步幅为 $s_h$ 、水平步幅为 $s_w$ 时，输出形状为\n","\n","$$\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor.$$\n","\n","如果我们设置了 $p_h=k_h-1$ 和 $p_w=k_w-1$，则输出形状将简化为 $\\lfloor(n_h+s_h-1)/s_h\\rfloor \\times \\lfloor(n_w+s_w-1)/s_w\\rfloor$。\n","更进一步，如果输入的高度和宽度可以被垂直和水平步幅整除，则输出形状将为 $(n_h/s_h) \\times (n_w/s_w)$。\n","\n","下面，我们将高度和宽度的步幅设置为 $2$，从而将输入的高度和宽度减半。\n"]},{"cell_type":"code","metadata":{"origin_pos":11,"tab":["tensorflow"],"id":"e_6iT0o1M4qx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407769,"user_tz":-480,"elapsed":8856,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"fb9d1dcc-2333-493d-b133-d2b464cf0377"},"source":["conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same', strides=2)\n","comp_conv2d(conv2d, X).shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([4, 4])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"origin_pos":12,"id":"CDTtAWb_M4qy"},"source":["接下来，看一个稍微复杂的例子。\n"]},{"cell_type":"code","metadata":{"origin_pos":15,"tab":["tensorflow"],"id":"EbkO0eKkM4qy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407769,"user_tz":-480,"elapsed":8849,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"ce2dbae8-e8de-4da0-cf64-1a502453658e"},"source":["conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3, 5), padding='valid',\n","                                strides=(3, 4))\n","comp_conv2d(conv2d, X).shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([2, 1])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"origin_pos":16,"id":"OBE1QcPyM4qy"},"source":["为了简洁起见，当输入高度和宽度两侧的填充数量分别为 $p_h$ 和 $p_w$ 时，我们称之为填充 $(p_h, p_w)$。当 $p_h = p_w = p$ 时，填充是 $p$。同理，当高度和宽度上的步幅分别为 $s_h$ 和 $s_w$ 时，我们称之为步幅 $(s_h, s_w)$。当时的步幅为 $s_h = s_w = s$ 时，步幅为 $s$。默认情况下，填充为 0，步幅为 1。在实践中，我们很少使用不一致的步幅或填充，也就是说，我们通常有 $p_h = p_w$ 和 $s_h = s_w$。\n","\n","\n","## 小结\n","\n","* 填充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。\n","* 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的 $1/n$（ $n$ 是一个大于 $1$ 的整数）。\n","* 填充和步幅可用于有效地调整数据的维度。"]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"SYQ5tbs2hWwS"},"source":["# 多输入多输出通道\n",":label:`sec_channels`\n","\n","虽然我们在 :numref:`subsec_why-conv-channels` 中描述了构成每个图像的多个通道和多层卷积层。例如彩色图像具有标准的 RGB 通道来指示红、绿和蓝。\n","但是到目前为止，我们仅展示了单个输入和单个输出通道的简化例子。\n","这使得我们可以将输入、卷积核和输出看作二维张量。\n","\n","当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有 $3\\times h\\times w$ 的形状。我们将这个大小为 $3$ 的轴称为 *通道*（channel） 维度。在本节中，我们将更深入地研究具有多输入和多输出通道的卷积核。\n","\n","\n","## 多输入通道\n","\n","当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数目的卷积核，以便与输入数据进行互相关运算。假设输入的通道数为 $c_i$，那么卷积核的输入通道数也需要为 $c_i$ 。如果卷积核的窗口形状是 $k_h\\times k_w$，那么当 $c_i=1$ 时，我们可以把卷积核看作形状为 $k_h\\times k_w$ 的二维张量。\n","\n","然而，当 $c_i>1$ 时，我们卷积核的每个输入通道将包含形状为 $k_h\\times k_w$ 的张量。将这些张量 $c_i$ 连结在一起可以得到形状为 $c_i\\times k_h\\times k_w$ 的卷积核。由于输入和卷积核都有 $c_i$ 个通道，我们可以对每个通道输入的二维张量和卷积核的二维张量进行互相关运算，再对通道求和（将 $c_i$ 的结果相加）得到二维张量。这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果。\n","\n","在 :numref:`fig_conv_multi_in` 中，我们演示了一个具有两个输入通道的二维互相关运算的示例。阴影部分是第一个输出元素以及用于计算这个输出的输入和核张量元素：$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$。\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_jTCkg-cbbeV"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"68XdkXUFbV_P"},"source":["为了加深理解，我们将多输入通道互相关运算实现一下。\n","简而言之，我们所做的就是对每个通道执行互相关操作，然后将结果相加。"]},{"cell_type":"code","metadata":{"origin_pos":4,"tab":["tensorflow"],"id":"5LNcl60yhWwS","executionInfo":{"status":"ok","timestamp":1617684407769,"user_tz":-480,"elapsed":8847,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["import tensorflow as tf\n","from d2l import tensorflow as d2l\n","\n","def corr2d_multi_in(X, K):\n","    # 先遍历 “X” 和 “K” 的第0个维度（通道维度），再把它们加在一起\n","    return tf.reduce_sum([d2l.corr2d(x, k) for x, k in zip(X, K)], axis=0)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":5,"id":"vwjQp38MhWwS"},"source":["我们可以构造与 :numref:`fig_conv_multi_in` 中的值相对应的输入张量 `X` 和核张量 `K`，以验证互相关运算的输出。\n"]},{"cell_type":"code","metadata":{"origin_pos":6,"tab":["tensorflow"],"id":"e9ideC65hWwS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407769,"user_tz":-480,"elapsed":8839,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"9e72c970-98aa-4eae-fe8b-ba4aaf4ab6a0"},"source":["X = tf.constant([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n","                 [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n","K = tf.constant([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n","\n","corr2d_multi_in(X, K)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[ 56.,  72.],\n","       [104., 120.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"origin_pos":7,"id":"vGzGiRCbhWwT"},"source":["## 多输出通道\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2k34fjS1hd9D"},"source":["\n","到目前为止，不论有多少输入通道，我们还只有一个输出通道。然而，正如我们在 :numref:`subsec_why-conv-channels` 中所讨论的，每一层有多个输出通道是至关重要的。在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。直观地说，我们可以将每个通道看作是对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器。\n","\n","用 $c_i$ 和 $c_o$ 分别表示输入和输出通道的数目，并让 $k_h$ 和 $k_w$ 为卷积核的高度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为 $c_i\\times k_h\\times k_w$ 的卷积核张量，这样卷积核的形状是 $c_o\\times c_i\\times k_h\\times k_w$。在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。\n","\n","如下所示，我们实现一个计算多个通道的输出的互相关函数。"]},{"cell_type":"code","metadata":{"origin_pos":8,"tab":["tensorflow"],"id":"bGH9amzEhWwT","executionInfo":{"status":"ok","timestamp":1617684407770,"user_tz":-480,"elapsed":8838,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["def corr2d_multi_in_out(X, K):\n","    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n","    # 最后将所有结果都叠加在一起\n","    return tf.stack([corr2d_multi_in(X, k) for k in K], 0)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":9,"id":"Qt6Oe56ehWwU"},"source":["通过将核张量 `K` 与 `K+1` （ `K` 中每个元素加 $1$ ）和 `K+2` 连接起来，构造了一个具有$3$个输出通道的卷积核。\n"]},{"cell_type":"code","metadata":{"origin_pos":10,"tab":["tensorflow"],"id":"4FzUjTKphWwU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407770,"user_tz":-480,"elapsed":8831,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"e3ad6572-1411-4d91-873f-890d136ce121"},"source":["K = tf.stack((K, K + 1, K + 2), 0)\n","K.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([3, 2, 2, 2])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"origin_pos":11,"id":"6fYxvjPShWwU"},"source":["下面，我们对输入张量 `X` 与卷积核张量 `K` 执行互相关运算。现在的输出包含 $3$ 个通道，第一个通道的结果与先前输入张量 `X` 和多输入单输出通道的结果一致。\n"]},{"cell_type":"code","metadata":{"origin_pos":12,"tab":["tensorflow"],"id":"HwGpF-V3hWwU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407770,"user_tz":-480,"elapsed":8824,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"586f5487-bdb7-41da-da20-39e542207cb3"},"source":["corr2d_multi_in_out(X, K)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n","array([[[ 56.,  72.],\n","        [104., 120.]],\n","\n","       [[ 76., 100.],\n","        [148., 172.]],\n","\n","       [[ 96., 128.],\n","        [192., 224.]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"origin_pos":13,"id":"HAb9w9_ehWwU"},"source":["## $1\\times 1$ 卷积层\n","\n","$1 \\times 1$ 卷积，即 $k_h = k_w = 1$，看起来似乎没有多大意义。毕竟，卷积的本质是有效提取相邻像素间的相关特征，而 $1 \\times 1$ 卷积显然没有此作用。\n","尽管如此，$1 \\times 1$ 仍然十分流行，时常包含在复杂深层网络的设计中。下面，让我们详细地解读一下它的实际作用。\n","\n","因为使用了最小窗口，$1\\times 1$ 卷积失去了卷积层的特有能力——在高度和宽度维度上，识别相邻元素间相互作用的能力。\n","而 $1\\times 1$ 卷积的唯一计算发生在通道上。\n","\n",":numref:`fig_conv_1x1` 展示了使用 $1\\times 1$ 卷积核与 $3$ 个输入通道和 $2$ 个输出通道的互相关计算。\n","这里输入和输出具有相同的高度和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合。\n","我们可以将 $1\\times 1$ 卷积层看作是在每个像素位置应用的全连接层，以 $c_i$ 个输入值转换为 $c_o$ 个输出值。\n","因为这仍然是一个卷积层，所以跨像素的权重是一致的。\n","同时，$1\\times 1$ 卷积层需要的权重维度为 $c_o\\times c_i$ ，再额外加上一个偏置。\n","\n","\n","![互相关计算使用了具有3个输入通道和2个输出通道的 $1\\times 1$ 卷积核。其中，输入和输出具有相同的高度和宽度。](../img/conv-1x1.svg)\n",":label:`fig_conv_1x1`\n","\n","下面，我们使用全连接层实现 $1 \\times 1$ 卷积。\n","请注意，我们需要对输入和输出的数据形状进行微调。\n"]},{"cell_type":"code","metadata":{"origin_pos":14,"tab":["tensorflow"],"id":"T7wQJrEthWwV","executionInfo":{"status":"ok","timestamp":1617684407771,"user_tz":-480,"elapsed":8824,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["def corr2d_multi_in_out_1x1(X, K):\n","    c_i, h, w = X.shape\n","    c_o = K.shape[0]\n","    X = tf.reshape(X, (c_i, h * w))\n","    K = tf.reshape(K, (c_o, c_i))\n","    Y = tf.matmul(K, X)  # 全连接层中的矩阵乘法\n","    return tf.reshape(Y, (c_o, h, w))"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":15,"id":"fnCKrZsUhWwV"},"source":["当执行 $1\\times 1$ 卷积运算时，上述函数相当于先前实现的互相关函数`corr2d_multi_in_out`。让我们用一些样本数据来验证这一点。\n"]},{"cell_type":"code","metadata":{"origin_pos":17,"tab":["tensorflow"],"id":"bIexBeZchWwV","executionInfo":{"status":"ok","timestamp":1617684407772,"user_tz":-480,"elapsed":8824,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["X = tf.random.normal((3, 3, 3), 0, 1)\n","K = tf.random.normal((2, 3, 1, 1), 0, 1)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"origin_pos":18,"tab":["tensorflow"],"id":"Tyl9_xvOhWwV","executionInfo":{"status":"ok","timestamp":1617684407772,"user_tz":-480,"elapsed":8822,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["Y1 = corr2d_multi_in_out_1x1(X, K)\n","Y2 = corr2d_multi_in_out(X, K)\n","assert float(tf.reduce_sum(tf.abs(Y1 - Y2))) < 1e-6"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":19,"id":"s8GGu7vBhWwV"},"source":["## 小结\n","\n","* 多输入多输出通道可以用来扩展卷积层的模型。\n","* 当以每像素为基础应用时，$1\\times 1$ 卷积层相当于全连接层。\n","* $1\\times 1$ 卷积层通常用于调整网络层的通道数量和控制模型复杂性。\n","\n","## 练习\n","\n","1. 假设我们有两个卷积核，大小分别为 $k_1$ 和 $k_2$（中间没有非线性激活函数）。\n","    1. 证明运算可以用单次卷积来表示。\n","    1. 这个等效的单卷积的维数是多少呢？\n","    1. 反之亦然吗？\n","1. 假设输入为 $c_i\\times h\\times w$，卷积核大小为 $c_o\\times c_i\\times k_h\\times k_w$，填充为 $(p_h, p_w)$，步幅为 $(s_h, s_w)$。\n","    1. 正向传播的计算成本（乘法和加法）是多少？\n","    1. 内存占用是多少？\n","    1. 反向传播的内存占用是多少？\n","    1. 反向传播的计算成本是多少？\n","1. 如果我们将输入通道 $c_i$ 和输出通道 $c_o$ 的数量加倍，计算数量会增加多少？如果我们把填充数量翻一番会怎么样？\n","1. 如果卷积核的高度和宽度是 $k_h=k_w=1$，前向传播的计算复杂度是多少？\n","1. 本节最后一个示例中的变量 `Y1` 和 `Y2` 是否完全相同？为什么？\n","1. 当卷积窗口不是 $1\\times 1$ 时，如何使用矩阵乘法实现卷积？\n"]},{"cell_type":"markdown","metadata":{"id":"hp1kTUQahnLG"},"source":["# 池化层\n"]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"1rDhOuXZhiHp"},"source":["通常当我们处理图像时，我们希望逐渐降低隐藏表示的空间分辨率，聚集信息，这样的随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野（输入）就越大。\n","\n","而我们的机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”）， 所以我们最后一层的神经元应该对整个输入的全局敏感。通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层。\n","\n","此外，当检测较底层的特征时（例如 :numref:`sec_conv_layer` 中所讨论的边缘），我们通常希望这些特征保持某种程度上的平移不变性。例如，如果我们拍摄黑白之间轮廓清晰的图像 `X`，并将整个图像向右移动一个像素，即 `Z[i, j] = X[i, j + 1]`，则新图像 `Z` 的输出可能大不相同。而在现实中，随着拍摄角度的移动，任何物体几乎不可能发生在同一像素上。即使用三脚架拍摄一个静止的物体，由于快门的移动而引起的相机振动，可能会使所有物体左右移动一个像素（除了高端相机配备了特殊功能来解决这个问题）。\n","\n","本节将介绍 *池化*（pooling）层，它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。\n","\n","\n","## 最大池化层和平均池化层\n","\n","与卷积层类似，池化层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口（有时称为 *池化窗口*）遍历的每个位置计算一个输出。\n","然而，不同于卷积层中的输入与卷积核之间的互相关计算，池化层不包含参数。\n","相反，池运算符是确定性的，我们通常计算池化窗口中所有元素的最大值或平均值。这些操作分别称为 *最大池化层* （maximum pooling）和 *平均池化层* （average pooling）。\n","\n","在这两种情况下，与互相关运算符一样，池化窗口从输入张量的左上角开始，从左到右、从上到下的在输入张量内滑动。在池化窗口到达的每个位置，它计算该窗口中输入子张量的最大值或平均值，具体取决于是使用了最大池化层还是平均池化层。\n","\n","\n","![池化窗口形状为 $2\\times 2$ 的最大池化层。着色部分是第一个输出元素，以及用于计算这个输出的输入元素: $\\max(0, 1, 3, 4)=4$.](http://d2l.ai/_images/pooling.svg)\n",":label:`fig_pooling`\n","\n",":numref:`fig_pooling` 中的输出张量的高度为 $2$，宽度为 $2$。这四个元素为每个池化窗口中的最大值：\n","\n","$$\n","\\max(0, 1, 3, 4)=4,\\\\\n","\\max(1, 2, 4, 5)=5,\\\\\n","\\max(3, 4, 6, 7)=7,\\\\\n","\\max(4, 5, 7, 8)=8.\\\\\n","$$\n","\n","池化窗口形状为 $p \\times q$ 的池化层称为 $p \\times q$ 池化层，池化操作称为 $p \\times q$ 池化。\n","\n","回到本节开头提到的对象边缘检测示例，现在我们将使用卷积层的输出作为 $2\\times 2$ 最大池化的输入。\n","设置卷积层输入为 `X`，池化层输出为 `Y`。\n","无论 `X[i, j]` 和 `X[i, j + 1]` 的值是否不同，或 `X[i, j + 1]` 和 `X[i, j + 2]` 的值是否不同，池化层始终输出 `Y[i, j] = 1`。\n","也就是说，使用 $2\\times 2$ 最大池化层，即使在高度或宽度上移动一个元素，卷积层仍然可以识别到模式。\n","\n","在下面的代码中的 `pool2d` 函数，实现了池化层的正向传播。\n","此功能类似于 :numref:`sec_conv_layer` 中的 `corr2d` 函数。\n","然而，这里我们没有卷积核，输出为输入中每个区域的最大值或平均值。\n"]},{"cell_type":"code","metadata":{"origin_pos":4,"tab":["tensorflow"],"id":"Oa3arydZhiHs","executionInfo":{"status":"ok","timestamp":1617684407772,"user_tz":-480,"elapsed":8821,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["import tensorflow as tf\n","\n","def pool2d(X, pool_size, mode='max'):\n","    p_h, p_w = pool_size\n","    Y = tf.Variable(tf.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            if mode == 'max':\n","                Y[i, j].assign(tf.reduce_max(X[i:i + p_h, j:j + p_w]))\n","            elif mode == 'avg':\n","                Y[i, j].assign(tf.reduce_mean(X[i:i + p_h, j:j + p_w]))\n","    return Y"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":5,"id":"4YkDpoi0hiHt"},"source":["我们可以构建 :numref:`fig_pooling` 中的输入张量 `X`，验证二维最大池化层的输出。\n"]},{"cell_type":"code","metadata":{"origin_pos":6,"tab":["tensorflow"],"id":"NQf1zoIwhiHt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407772,"user_tz":-480,"elapsed":8814,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"0dede2a2-22ea-454e-d505-b27c05e28d23"},"source":["X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","pool2d(X, (2, 2))"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[4., 5.],\n","       [7., 8.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"origin_pos":7,"id":"OlfZ650bhiHu"},"source":["此外，我们还可以验证平均池化层。\n"]},{"cell_type":"code","metadata":{"origin_pos":8,"tab":["tensorflow"],"id":"NfhY_n4KhiHu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407773,"user_tz":-480,"elapsed":8808,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"22bf79f0-12a0-453c-dcd6-f0466c62abc0"},"source":["pool2d(X, (2, 2), 'avg')"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[2., 3.],\n","       [5., 6.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"origin_pos":9,"id":"BKL2KjTrhiHv"},"source":["## 填充和步幅\n","\n","与卷积层一样，池化层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。\n","下面，我们用深度学习框架中内置的二维最大池化层，来演示池化层中填充和步幅的使用。\n","我们首先构造了一个输入张量 `X`，它有四个维度，其中样本数和通道数都是 1。\n"]},{"cell_type":"code","metadata":{"origin_pos":11,"tab":["tensorflow"],"id":"tmslgvUJhiHv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407773,"user_tz":-480,"elapsed":8801,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"be52b9bc-4465-46bd-c65d-f1537c72d058"},"source":["X = tf.reshape(tf.range(16, dtype=tf.float32), (1, 4, 4, 1))\n","X"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 4, 4, 1), dtype=float32, numpy=\n","array([[[[ 0.],\n","         [ 1.],\n","         [ 2.],\n","         [ 3.]],\n","\n","        [[ 4.],\n","         [ 5.],\n","         [ 6.],\n","         [ 7.]],\n","\n","        [[ 8.],\n","         [ 9.],\n","         [10.],\n","         [11.]],\n","\n","        [[12.],\n","         [13.],\n","         [14.],\n","         [15.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"origin_pos":12,"id":"j6oxLOQehiHv"},"source":["默认情况下，深度学习框架中的步幅与池化窗口的大小相同。\n","因此，如果我们使用形状为 `(3, 3)` 的池化窗口，那么默认情况下，我们得到的步幅形状为 `(3, 3)`。\n"]},{"cell_type":"code","metadata":{"origin_pos":15,"tab":["tensorflow"],"id":"opE-o5g1hiHv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407773,"user_tz":-480,"elapsed":8794,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"81f10a2a-3c2f-4318-9550-8adff95aad37"},"source":["pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3])\n","pool2d(X)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[10.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"origin_pos":16,"id":"ERuWTZvYhiHv"},"source":["填充和步幅可以手动设定。\n"]},{"cell_type":"code","metadata":{"origin_pos":19,"tab":["tensorflow"],"id":"jxxOdC3thiHw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407774,"user_tz":-480,"elapsed":8788,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"405951c1-72e9-482f-ceb1-7b04353315cd"},"source":["pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3], padding='same',\n","                                   strides=2)\n","pool2d(X)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n","array([[[[10.],\n","         [11.]],\n","\n","        [[14.],\n","         [15.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"origin_pos":20,"id":"Nv4-TMp3hiHw"},"source":["当然，我们可以设定一个任意大小的矩形池化窗口，并分别设定填充和步幅的高度和宽度。\n"]},{"cell_type":"code","metadata":{"origin_pos":23,"tab":["tensorflow"],"id":"AX8yxXrFhiHw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407774,"user_tz":-480,"elapsed":8781,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"a243dbe1-0a76-41de-f47b-54207e83594c"},"source":["pool2d = tf.keras.layers.MaxPool2D(pool_size=[2, 3], padding='same',\n","                                   strides=(2, 3))\n","pool2d(X)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n","array([[[[ 5.],\n","         [ 7.]],\n","\n","        [[13.],\n","         [15.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"origin_pos":24,"id":"TGLoG38rhiHw"},"source":["## 多个通道\n","\n","在处理多通道输入数据时，池化层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总。\n","这意味着池化层的输出通道数与输入通道数相同。\n","下面，我们将在通道维度上连结张量 `X` 和 `X + 1`，以构建具有 2 个通道的输入。\n"]},{"cell_type":"code","metadata":{"origin_pos":26,"tab":["tensorflow"],"id":"k258_uxmhiHw","executionInfo":{"status":"ok","timestamp":1617684407774,"user_tz":-480,"elapsed":8780,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["X = tf.reshape(tf.stack([X, X + 1], 0), (1, 2, 4, 4))"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":27,"id":"GXqSmoW9hiHx"},"source":["如下所示，池化后输出通道的数量仍然是 2。\n"]},{"cell_type":"code","metadata":{"origin_pos":30,"tab":["tensorflow"],"id":"3ZuLXFX-hiHx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407775,"user_tz":-480,"elapsed":8774,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"1aaa8f93-2443-462d-a3b6-e22239dd6374"},"source":["pool2d = tf.keras.layers.MaxPool2D(3, padding='same', strides=2)\n","pool2d(X)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1, 2, 4), dtype=float32, numpy=\n","array([[[[ 9., 10., 11., 12.],\n","         [13., 14., 15., 16.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"origin_pos":31,"id":"rx03WmCIhiHx"},"source":["## 小结\n","\n","* 对于给定输入元素，最大池化层会输出该窗口内的最大值，平均池化层会输出该窗口内的平均值。\n","* 池化层的主要优点之一是减轻卷积层对位置的过度敏感。\n","* 我们可以指定池化层的填充和步幅。\n","* 使用最大池化层以及大于 1 的步幅，可减少空间维度（如高度和宽度）。\n","* 池化层的输出通道数与输入通道数相同。\n","\n","\n","## 练习\n","\n","1. 你能将平均池化层作为卷积层的特殊情况实现吗？\n","1. 你能将最大池化层作为卷积层的特殊情况实现吗？\n","1. 假设池化层的输入大小为 $c\\times h\\times w$，则池化窗口的形状为 $p_h\\times p_w$，填充为 $(p_h, p_w)$，步幅为 $(s_h, s_w)$。这个池化层的计算成本是多少？\n","1. 为什么最大池化层和平均池化层的工作方式不同？\n","1. 我们是否需要最小池化层？可以用已知函数替换它吗？\n","1. 除了平均池化层和最大池化层，是否有其它函数可以考虑（提示：回忆 `softmax` ）？为什么它可能不受欢迎？\n"]},{"cell_type":"markdown","metadata":{"id":"5F_vEWAshxyl"},"source":["# 卷积神经网络（LeNet）"]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"47dkn18RhsK0"},"source":["## LeNet\n","\n","总体来看，LeNet (LeNet-5) 由两个部分组成：\n","\n","* 卷积编码器：由两个卷积层组成;\n","* 全连接层密集块：由三个全连接层组成。\n","\n","该结构在 :numref:`img_lenet` 中所展示。\n","\n","![LeNet中的数据流。输入是手写数字，输出为10种可能结果的概率。](http://d2l.ai/_images/lenet.svg)\n",":label:`img_lenet`\n","\n","每个卷积块中的基本单元是一个卷积层、一个 sigmoid 激活函数和平均池化层。请注意，虽然 ReLU 和最大池化层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用 $5\\times 5$ 卷积核，这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有 6 个输出通道，而第二个卷积层有 16 个输出通道。每个 $2\\times2$ 池操作（步骤2）通过空间下采样将维数减少 4 倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。\n","\n","为了将卷积块的输出传递给稠密块，我们必须在小批量中展平每个样本。换言之，我们将这个四维输入转换成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。LeNet 的稠密块有三个全连接层，分别有 120、84 和 10 个输出。因为我们仍在执行分类，所以输出层的 10 维对应于最后输出结果的数量。\n","\n","通过下面的 LeNet 代码，你会相信用深度学习框架实现此类模型非常简单。我们只需要实例化一个 `Sequential` 块并将需要的层连接在一起。\n"]},{"cell_type":"code","metadata":{"origin_pos":3,"tab":["tensorflow"],"id":"Za7am_OJhsK0","executionInfo":{"status":"ok","timestamp":1617684407775,"user_tz":-480,"elapsed":8772,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["import tensorflow as tf\n","from d2l import tensorflow as d2l\n","\n","def net():\n","    return tf.keras.models.Sequential([\n","        tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid',\n","                               padding='same'),\n","        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n","        tf.keras.layers.Conv2D(filters=16, kernel_size=5,\n","                               activation='sigmoid'),\n","        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(120, activation='sigmoid'),\n","        tf.keras.layers.Dense(84, activation='sigmoid'),\n","        tf.keras.layers.Dense(10)])"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":4,"id":"qnWQcKFxhsK0"},"source":["我们对原始模型做了一点小改动，去掉了最后一层的高斯激活。除此之外，这个网络与最初的 LeNet-5 一致。\n","\n","下面，我们将一个大小为 $28 \\times 28$ 的单通道（黑白）图像通过 LeNet。 通过在每一层打印输出的形状，我们可以检查模型，以确保其操作与我们期望的 :numref:`img_lenet_vert` 一致。\n","\n","![LeNet 的简化版。](../img/lenet-vert.svg)\n",":label:`img_lenet_vert`\n"]},{"cell_type":"code","metadata":{"origin_pos":7,"tab":["tensorflow"],"id":"nfAXtHOIhsK1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684407775,"user_tz":-480,"elapsed":8764,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"b4ad39be-a0da-461a-b51d-33fd70ad3dcc"},"source":["X = tf.random.uniform((1, 28, 28, 1))\n","for layer in net().layers:\n","    X = layer(X)\n","    print(layer.__class__.__name__, 'output shape: \\t', X.shape)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Conv2D output shape: \t (1, 28, 28, 6)\n","AveragePooling2D output shape: \t (1, 14, 14, 6)\n","Conv2D output shape: \t (1, 10, 10, 16)\n","AveragePooling2D output shape: \t (1, 5, 5, 16)\n","Flatten output shape: \t (1, 400)\n","Dense output shape: \t (1, 120)\n","Dense output shape: \t (1, 84)\n","Dense output shape: \t (1, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":8,"id":"2gYU4GTQhsK1"},"source":["请注意，在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。\n","第一个卷积层使用 2 个像素的填充，来补偿 $5 \\times 5$ 卷积核导致的特征减少。\n","相反，第二个卷积层没有填充，因此高度和宽度都减少了 4 个像素。\n","随着层叠的上升，通道的数量从输入时的 1 个，增加到第一个卷积层之后的 6 个，再到第二个卷积层之后的 16 个。\n","同时，每个池化层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果分类数相匹配的输出。\n","\n","\n","## 模型训练\n","\n","现在我们已经实现了 LeNet ，让我们看看这个模型在 Fashion-MNIST 数据集上的表现。\n"]},{"cell_type":"code","metadata":{"origin_pos":9,"tab":["tensorflow"],"id":"M9DWodijhsK2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617684409468,"user_tz":-480,"elapsed":10456,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"97780f9e-c9e1-4564-d378-9b6ce5fd8ce2"},"source":["batch_size = 256\n","train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":10,"id":"DiapRJPihsK2"},"source":["虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法。\n","如果你有机会使用GPU，可以用它加快训练。\n"]},{"cell_type":"markdown","metadata":{"origin_pos":14,"id":"L0qX6_DIhsK2"},"source":["为了使用 GPU，我们还需要一点小改动。\n","与 :numref:`sec_softmax_scratch` 中定义的 `train_epoch_ch3` 不同，在进行正向和反向传播之前，我们需要将每一小批量数据移动到我们指定的设备（例如 GPU）上。\n","\n","如下所示，训练函数 `train_ch6` 也类似于 :numref:`sec_softmax_scratch` 中定义的 `train_ch3` 。\n","由于我们将实现多层神经网络，因此我们将主要使用高级 API。\n","以下训练函数假定从高级 API 创建的模型作为输入，并进行相应的优化。\n","我们使用在 :numref:`subsec_xavier` 中介绍的 Xavier 随机初始化模型参数。\n","与全连接层一样，我们使用交叉熵损失函数和小批量随机梯度下降。\n"]},{"cell_type":"code","metadata":{"origin_pos":17,"tab":["tensorflow"],"id":"wPq24Y8RhsK2","executionInfo":{"status":"ok","timestamp":1617684410017,"user_tz":-480,"elapsed":11004,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}}},"source":["class TrainCallback(tf.keras.callbacks.Callback):  #@save\n","    \"\"\"A callback to visiualize the training progress.\"\"\"\n","    def __init__(self, net, train_iter, test_iter, num_epochs, device_name):\n","        self.timer = d2l.Timer()\n","        self.animator = d2l.Animator(\n","            xlabel='epoch', xlim=[1, num_epochs],\n","            legend=['train loss', 'train acc', 'test acc'])\n","        self.net = net\n","        self.train_iter = train_iter\n","        self.test_iter = test_iter\n","        self.num_epochs = num_epochs\n","        self.device_name = device_name\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        self.timer.start()\n","\n","    def on_epoch_end(self, epoch, logs):\n","        self.timer.stop()\n","        test_acc = self.net.evaluate(self.test_iter, verbose=0,\n","                                     return_dict=True)['accuracy']\n","        metrics = (logs['loss'], logs['accuracy'], test_acc)\n","        self.animator.add(epoch + 1, metrics)\n","        if epoch == self.num_epochs - 1:\n","            batch_size = next(iter(self.train_iter))[0].shape[0]\n","            num_examples = batch_size * tf.data.experimental.cardinality(\n","                self.train_iter).numpy()\n","            print(f'loss {metrics[0]:.3f}, train acc {metrics[1]:.3f}, '\n","                  f'test acc {metrics[2]:.3f}')\n","            print(f'{num_examples / self.timer.avg():.1f} examples/sec on '\n","                  f'{str(self.device_name)}')\n","\n","#@save\n","def train_ch6(net_fn, train_iter, test_iter, num_epochs, lr, device):\n","    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n","    device_name = device._device_name\n","    strategy = tf.distribute.OneDeviceStrategy(device_name)\n","    with strategy.scope():\n","        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n","        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        net = net_fn()\n","        net.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","    callback = TrainCallback(net, train_iter, test_iter, num_epochs,\n","                             device_name)\n","    net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\n","    return net"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":18,"id":"BrRnvfwchsK3"},"source":["现在，我们训练和评估 LeNet-5 模型。\n"]},{"cell_type":"code","metadata":{"origin_pos":19,"tab":["tensorflow"],"id":"SUhSjxbNhsK3","colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"status":"ok","timestamp":1617684707812,"user_tz":-480,"elapsed":308792,"user":{"displayName":"黄不盈","photoUrl":"","userId":"09846410536788032197"}},"outputId":"9aa6ba33-cbf2-4fe7-c80f-8e0e8d76997c"},"source":["lr, num_epochs = 0.9, 10\n","train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"],"execution_count":36,"outputs":[{"output_type":"stream","text":["loss 0.473, train acc 0.822, test acc 0.819\n","2214.4 examples/sec on /CPU:0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1850814f90>"]},"metadata":{"tags":[]},"execution_count":36},{"output_type":"display_data","data":{"text/plain":["<Figure size 252x180 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 238.965625 180.65625\" width=\"238.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 238.965625 180.65625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 51.803125 143.1 \nL 51.803125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m98c0da85a3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.803125\" xlink:href=\"#m98c0da85a3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(48.621875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 95.203125 143.1 \nL 95.203125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.203125\" xlink:href=\"#m98c0da85a3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(92.021875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 138.603125 143.1 \nL 138.603125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.603125\" xlink:href=\"#m98c0da85a3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(135.421875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 182.003125 143.1 \nL 182.003125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.003125\" xlink:href=\"#m98c0da85a3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(178.821875 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.403125\" xlink:href=\"#m98c0da85a3\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(219.040625 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(112.525 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 142.483979 \nL 225.403125 142.483979 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m5933d8d05e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5933d8d05e\" y=\"142.483979\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 146.283198)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 114.67772 \nL 225.403125 114.67772 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5933d8d05e\" y=\"114.67772\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 118.476939)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 86.871461 \nL 225.403125 86.871461 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5933d8d05e\" y=\"86.871461\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 90.670679)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 59.065201 \nL 225.403125 59.065201 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5933d8d05e\" y=\"59.065201\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 62.86442)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 31.258942 \nL 225.403125 31.258942 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5933d8d05e\" y=\"31.258942\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 35.058161)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 13.377273 \nL 51.803125 46.880611 \nL 73.503125 91.544877 \nL 95.203125 101.487463 \nL 116.903125 105.601023 \nL 138.603125 108.448455 \nL 160.303125 111.160844 \nL 182.003125 112.976603 \nL 203.703125 114.785183 \nL 225.403125 116.194583 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 136.754036 \nL 51.803125 123.63875 \nL 73.503125 106.952214 \nL 95.203125 102.869329 \nL 116.903125 101.280665 \nL 138.603125 100.173047 \nL 160.303125 98.945864 \nL 182.003125 98.147825 \nL 203.703125 97.375737 \nL 225.403125 96.770487 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#pb8b2441d12)\" d=\"M 30.103125 136.922727 \nL 51.803125 109.833868 \nL 73.503125 103.755422 \nL 95.203125 102.170464 \nL 116.903125 100.123925 \nL 138.603125 100.224028 \nL 160.303125 99.71239 \nL 182.003125 98.46111 \nL 203.703125 97.376665 \nL 225.403125 96.931764 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 143.1 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 140.634375 59.234375 \nL 218.403125 59.234375 \nQ 220.403125 59.234375 220.403125 57.234375 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 140.634375 12.2 \nQ 138.634375 12.2 138.634375 14.2 \nL 138.634375 57.234375 \nQ 138.634375 59.234375 140.634375 59.234375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 142.634375 20.298438 \nL 162.634375 20.298438 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_25\"/>\n    <g id=\"text_12\">\n     <!-- train loss -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(170.634375 23.798438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"292.333984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"353.515625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"405.615234\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 142.634375 34.976562 \nL 162.634375 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_27\"/>\n    <g id=\"text_13\">\n     <!-- train acc -->\n     <g transform=\"translate(170.634375 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"325.830078\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"380.810547\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n    <g id=\"line2d_28\">\n     <path d=\"M 142.634375 49.654688 \nL 162.634375 49.654688 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_29\"/>\n    <g id=\"text_14\">\n     <!-- test acc -->\n     <g transform=\"translate(170.634375 53.154688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"285.107422\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"340.087891\" xlink:href=\"#DejaVuSans-99\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb8b2441d12\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"origin_pos":20,"id":"bAaPFnNrhsK3"},"source":["## 小结\n","\n","* 卷积神经网络（CNN）是一类使用卷积层的网络。\n","* 在卷积神经网络中，我们组合使用卷积层、非线性激活函数和池化层。\n","* 为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。\n","* 在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。\n","* LeNet是最早发布的卷积神经网络之一。\n","\n","## 练习\n","\n","1. 将平均池化层替换为最大池化层，会发生什么？\n","1. 尝试构建一个基于 LeNet 的更复杂的网络，以提高其准确性。\n","    1. 调整卷积窗口大小。\n","    1. 调整输出通道的数量。\n","    1. 调整激活函数（如 ReLU）。\n","    1. 调整卷积层的数量。\n","    1. 调整全连接层的数量。\n","    1. 调整学习率和其他训练细节（例如，初始化和周期数）。\n","1. 在 MNIST 数据集上尝试以上改进的网络。\n","1. 显示不同输入（例如毛衣和外套）时，LeNet 第一层和第二层的激活值。\n"]}]}